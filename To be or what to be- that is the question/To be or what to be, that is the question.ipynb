{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "rcorpus = open('corpus.txt', 'r', encoding='utf-8-sig').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_m_r = '\\n{3,}\\s+THE SECRET CACHE\\n{3,}.*'\n",
    "corpus = re.search(t_m_r, rcorpus, flags=re.M+re.S).group()\n",
    "corpus = corpus.replace('\\n', ' ') \n",
    "corpus = re.sub(r' {2,}', ' ', corpus) \n",
    "corpus = corpus.replace('----', '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_forms = ['am','are','were','was','is','been','being','be']\n",
    "substitute = '----'\n",
    "tokens = wordpunct_tokenize(corpus)\n",
    "def find(tokens):\n",
    "    return [t for t in tokens if t in be_forms]\n",
    "    \n",
    "def remove(tokens):\n",
    "    \"\"\" Replace targets with a substitute in a tokenized text\"\"\"\n",
    "    return [substitute if t in be_forms else t for t in tokens]\n",
    "targets = find(tokens)\n",
    "tokens = remove(tokens)\n",
    "def create_windows(tokens, window_size=5):\n",
    "    \"\"\" Create windows surrouding be forms. \"\"\"\n",
    "    contexts = []\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word == substitute:\n",
    "            window = tokens[i-window_size:i] + tokens[i+1:i+window_size+1]\n",
    "            window = ' '.join(window)\n",
    "            contexts.append(window)    \n",
    "    return contexts\n",
    "contexts = create_windows(tokens)\n",
    "\n",
    "\n",
    "count = np.unique(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "contexts_train, contexts_test, y_train, y_test = train_test_split(contexts, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "pipe = make_pipeline(vectorizer, classifier)\n",
    "pipe.fit(contexts_train, y_train)\n",
    "y_pred = pipe.predict(contexts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was\n",
      "was\n",
      "was\n",
      "was\n",
      "was\n",
      "was\n"
     ]
    }
   ],
   "source": [
    "sample = open('Sample-Input.txt', 'r', encoding='utf-8-sig').read().splitlines()\n",
    "N = int(sample[0])\n",
    "sample = sample[1]\n",
    "sample = wordpunct_tokenize(sample)\n",
    "contexts_sample = create_windows(sample)\n",
    "sample_pred = encoder.inverse_transform(pipe.predict(contexts_sample))\n",
    "print('\\n'.join(sample_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
